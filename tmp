Master main
- name: Initialize the Kubernetes cluster using kubeadm
  command: kubeadm init --apiserver-advertise-address="{{ node_ip }}" --apiserver-cert-extra-sans="{{ node_ip }}"  --node-name="{{ node_name }}" --pod-network-cidr={{ pod_network }}

- name: Setup kubeconfig for vagrant user
  command: "{{ item }}"
  with_items:
    - mkdir -p /home/vagrant/.kube
    - cp -i /etc/kubernetes/admin.conf /home/vagrant/.kube/config
    - chown vagrant:vagrant /home/vagrant/.kube
    - chown vagrant:vagrant /home/vagrant/.kube/config

- name: Add CNI - Install flannel pod network
  become: false
  environment:
    KUBECONFIG: /home/vagrant/.kube/config
  command: kubectl apply -f deployment/kube-flannel.yml
  # or remote file
  #command: kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# Other options for Container Network Interface
#- name: Add CNI - kuberouter
#  shell: kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml

- name: Generate join command
  command: kubeadm token create --print-join-command
  register: join_command

- name: Copy join command to local file
  become: false
  local_action: copy content="{{ join_command.stdout_lines[0] }}" dest="./join-command"

Tasks main
- name: Copy the join command to server location
  copy: src=join-command dest=/tmp/join-command.sh mode=0777

- name: Join the node to cluster
  command: sh /tmp/join-command.sh

Vagrantfile
# ####################################################################
# ################### CONFIGURATION VARIABLES ########################
# ####################################################################

IMAGE_NAME = "bento/ubuntu-18.04"   # Image to use
MEM = 4096                          # Amount of RAM
CPU = 2                             # Number of processors (Minimum value of 2 otherwise it will not work)
MASTER_NAME="master"                # Master node name
WORKER_NBR = 1                      # Number of workers node
NODE_NETWORK_BASE = "192.168.56"    # First three octets of the IP address that will be assign to all type of nodes
POD_NETWORK = "10.244.0.0/16"       # Private network for inter-pod communication

# ######################## START VAGRANT #############################

Vagrant.configure("2") do |config|
    config.ssh.insert_key = false

    # RAM and CPU config
    config.vm.provider "virtualbox" do |v|
        v.memory = MEM
        v.cpus = CPU
    end

    # Master node config
    config.vm.define MASTER_NAME do |master|
        
        # Hostname and network config
        master.vm.box = IMAGE_NAME
        master.vm.network "private_network", ip: "#{NODE_NETWORK_BASE}.10"
        master.vm.hostname = MASTER_NAME

        # Ansible role setting
        master.vm.provision "ansible" do |ansible|

            # Add debug mode
            #ansible.verbose = "vvv"

            ansible.compatibility_mode = "2.0"
            
            # Ansbile role that will be launched
            ansible.playbook = "roles/main.yml"

            # Groups in Ansible inventory
            ansible.groups = {
                "masters" => ["#{MASTER_NAME}"],
                "workers" => ["worker-[1:#{WORKER_NBR}]"]
            }

            # Overload Ansible variables
            ansible.extra_vars = {
                node_ip: "#{NODE_NETWORK_BASE}.10",
                node_name: "master",
                pod_network: "#{POD_NETWORK}"
            }
        end
    end

    # Worker node config
    (1..WORKER_NBR).each do |i|
        config.vm.define "worker-#{i}" do |worker|

            # Hostname and network config
            worker.vm.box = IMAGE_NAME
            worker.vm.network "private_network", ip: "#{NODE_NETWORK_BASE}.#{i + 10}"
            worker.vm.hostname = "worker-#{i}"

            # Ansible role setting
            worker.vm.provision "ansible" do |ansible|

                # Ansbile role that will be launched
                ansible.playbook = "roles/main.yml"

                # Groups in Ansible inventory
                ansible.groups = {
                    "masters" => ["#{MASTER_NAME}"],
                    "workers" => ["worker-[1:#{WORKER_NBR}]"]
                }

                # Overload Anqible variables
                ansible.extra_vars = {
                    node_ip: "#{NODE_NETWORK_BASE}.#{i + 10}"
                }
            end
        end
    end
end

Common main
- name: Install packages that allow apt to be used over HTTPS
  apt: 
    name='{{ item.name }}'
    state=present
    update_cache=yes
  with_items: "{{ https_packages | default([]) }}"

- name: Add new repositories keys
  apt_key:
    url='{{item.key}}'
    state=present
  with_items: "{{ gpg_keys | default([]) }}"

- name: Add new apt repositories
  apt_repository:
    repo='{{item.repo}}'
    state=present
  with_items: "{{ repositories | default([]) }}"

- name: Install docker
  apt: 
    name="{{ item.name }}"
    state=present
    update_cache=yes
  with_items: "{{ docker_packages | default([]) }}"
  notify:
    - docker status

- name: Change Docker cgroup driver - Create daemon.json file
  file:
    path: "/etc/docker/daemon.json"
    state: touch

- name: Change Docker cgroup driver - Edit daemon.json file
  blockinfile:
    path: "/etc/docker/daemon.json"
    block: |
            {
               "exec-opts": ["native.cgroupdriver=systemd"]
             }
    marker: ""

- name: Restart service docker
  systemd:
    state: restarted
    daemon_reload: yes
    name: docker

- name: Add vagrant user to docker group
  user:
    name: vagrant
    group: docker

- name: Remove swapfile from /etc/fstab
  mount:
    name: "{{ item }}"
    fstype: swap
    state: absent
  with_items:
    - swap
    - none

- name: Disable swap
  command: swapoff -a
  when: ansible_swaptotal_mb > 0

- name: Install Kubernetes binaries
  apt: 
    name="{{ item.name }}"
    state=present
    update_cache=yes
  with_items: "{{ k8s_packages | default([]) }}"

- name: Configure node ip
  lineinfile:
    path: '/etc/systemd/system/kubelet.service.d/10-kubeadm.conf'
    line: 'Environment="KUBELET_EXTRA_ARGS=--node-ip={{ node_ip }}"'
    regexp: 'KUBELET_EXTRA_ARGS='
    insertafter: '\[Service\]'
    state: present
  notify:
    - restart kubelet

- name: Remove containerd config file config.toml # issues ubuntu containerd
  ansible.builtin.file:
    path: /etc/containerd/config.toml
    state: absent
  notify:
    - restart containerd

- name: Create empty file config.toml
  file:
    path: "/etc/containerd/config.toml"
    state: touch

- name: Insert default config file for containerd
  ansible.builtin.shell: "containerd config default | sudo tee /etc/containerd/config.toml"

- name: restart containerd
  systemd:
    name: containerd
    state: restarted
    daemon_reload: yes

common handlers
- name: restart kubelet
  service: 
    name: kubelet 
    state: restarted 
    daemon_reload: yes

- name: restart containerd
  systemd:
    name: containerd
    state: restarted
    daemon_reload: yes

- name: restart service docker
  systemd:
    name: docker
    state: restarted
    daemon_reload: yes
    
- name: docker status
  service: 
    name: docker 
    state: started

default main
gpg_keys:
- key: https://download.docker.com/linux/ubuntu/gpg
- key: https://packages.cloud.google.com/apt/doc/apt-key.gpg

repositories:
- repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ansible_distribution_release}} stable"
- repo: "deb https://apt.kubernetes.io/ kubernetes-xenial main"

https_packages:
- name: apt-transport-https
- name: ca-certificates
- name: curl
- name: software-properties-common
- name: gnupg

docker_packages:
- name: docker-ce
- name: docker-ce-cli 
- name: containerd.io

k8s_packages:
- name: kubeadm
- name: kubelet
- name: kubectl

/deployment
kube-flannel.yml
---
kind: Namespace
apiVersion: v1
metadata:
  name: kube-flannel
  labels:
    k8s-app: flannel
    pod-security.kubernetes.io/enforce: privileged
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: flannel
  name: flannel
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes/status
  verbs:
  - patch
- apiGroups:
  - networking.k8s.io
  resources:
  - clustercidrs
  verbs:
  - list
  - watch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: flannel
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-flannel
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: flannel
  name: flannel
  namespace: kube-flannel
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: kube-flannel-cfg
  namespace: kube-flannel
  labels:
    tier: node
    k8s-app: flannel
    app: flannel
data:
  cni-conf.json: |
    {
      "name": "cbr0",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds
  namespace: kube-flannel
  labels:
    tier: node
    app: flannel
    k8s-app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/os
                operator: In
                values:
                - linux
      hostNetwork: true
      priorityClassName: system-node-critical
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni-plugin
        image: docker.io/flannel/flannel-cni-plugin:v1.2.0
        command:
        - cp
        args:
        - -f
        - /flannel
        - /opt/cni/bin/flannel
        volumeMounts:
        - name: cni-plugin
          mountPath: /opt/cni/bin
      - name: install-cni
        image: docker.io/flannel/flannel:v0.24.0
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: docker.io/flannel/flannel:v0.24.0
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
            add: ["NET_ADMIN", "NET_RAW"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: EVENT_QUEUE_DEPTH
          value: "5000"
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
        - name: xtables-lock
          mountPath: /run/xtables.lock
      volumes:
      - name: run
        hostPath:
          path: /run/flannel
      - name: cni-plugin
        hostPath:
          path: /opt/cni/bin
      - name: cni
        hostPath:
          path: /etc/cni/net.d
      - name: flannel-cfg
        configMap:
          name: kube-flannel-cfg
      - name: xtables-lock
        hostPath:
          path: /run/xtables.lock
          type: FileOrCreate
